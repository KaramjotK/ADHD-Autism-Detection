{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1FHDwFhXzyxGwAcf_B7ZuO3tDMd9KlJOK","timestamp":1718699037180}],"mount_file_id":"1-s3dcfOvAjIYzkPo8XtkExQQCQVyv2m1","authorship_tag":"ABX9TyO2AguR1LO2bZ7dwTZBt1kj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tMWmNsz6x67","executionInfo":{"status":"ok","timestamp":1717666815474,"user_tz":-330,"elapsed":23457,"user":{"displayName":"Karamjot","userId":"14290690433704537570"}},"outputId":"6c47fcdb-6093-4115-830a-1d88344ac951"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["vgg without se (single - channel)"],"metadata":{"id":"JT3Cs0u7i89S"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"u03IQDMNgVTw"},"outputs":[],"source":["import tensorflow as tf\n","from keras.layers import Conv3D, Dense, MaxPooling3D, Flatten, Dropout, BatchNormalization, LeakyReLU\n","from keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from keras.losses import binary_crossentropy, categorical_crossentropy\n","from tensorflow.keras.layers import Input, GlobalAveragePooling2D, MaxPooling2D, Conv2D\n","from keras.applications.vgg16 import VGG16\n","\n","from keras.applications.vgg16 import preprocess_input\n","\n","import numpy as np\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n","from sklearn.metrics import roc_curve, auc\n","from sklearn import metrics as mt\n","\n","import os\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from matplotlib import pyplot as plt\n","\n","import csv"]},{"cell_type":"code","source":["# adam optimizer default learning rate = 0.001\n","lr = 0.0001 #learning rate\n","ep = 1\n","batch_size = 1\n","n_splits = 5"],"metadata":{"id":"claRr50Ggsp0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_model(input_shape, num_classes):\n","\n","    inputs = Input(shape=input_shape)\n","\n","    x = Conv2D(32, (3, 3), strides=(1, 1), padding='same')(inputs)\n","    x = Conv2D(32, (3, 3), strides=(1, 1), padding='same')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n","\n","    x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n","    x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n","\n","    x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n","    x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n","    x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n","\n","    x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n","    x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n","    x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n","\n","    x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n","    x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n","    x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n","\n","    x = Conv2D(2048, (3, 3), strides=(1, 1), padding='same')(x)\n","    x = Conv2D(1024, (3, 3), strides=(1, 1), padding='same')(x)\n","\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(1024, activation='relu')(x)\n","    x = Dense(512, activation='relu')(x)\n","\n","    outputs = Dense(num_classes, activation='softmax')(x)  # Adjust num_classes according to your task\n","\n","    model = Model(inputs=inputs, outputs=outputs)\n","\n","    model.compile(optimizer=Adam(learning_rate = lr), loss='categorical_crossentropy', metrics=['accuracy'])\n","    print(\"Output shape of the model:\", model.output_shape)\n","    print(model.summary)\n","\n","    return model"],"metadata":{"id":"_HH3CJSXgskq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compile_fit(model, X_train, y_train, X_val, y_val):\n","\n","    hist = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=ep, batch_size=batch_size)\n","\n","    return model, hist"],"metadata":{"id":"tvCCw0z4gsiS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_history(hist, n):\n","    fig, ax = plt.subplots(2)\n","    ax[0].plot(hist.history['accuracy'], color=\"blue\")\n","    ax[0].plot(hist.history['val_accuracy'], color=\"green\")\n","    ax[0].set(xlabel=\"epochs\", ylabel=\"Accuracy\")\n","    ax[0].set_xlim((0,ep))\n","    ax[0].set_ylim((0,1))\n","    ax[0].legend(['training', 'testing'])\n","    ax[0].set_title(\"Accuracy Trend\")\n","\n","    ax[1].plot(hist.history['loss'], color=\"blue\")\n","    ax[1].plot(hist.history['val_loss'], color=\"green\")\n","    ax[1].set(xlabel=\"epochs\", ylabel=\"Loss\")\n","    ax[1].set_xlim((0,ep))\n","    ax[1].set_ylim((0,1))\n","    ax[1].legend(['training', 'testing'])\n","    ax[1].set_title(\"Loss Trend\")\n","\n","    fig.tight_layout(pad=2.0)\n","    plt.show()"],"metadata":{"id":"HmRBDNxVgsfy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def eval_model(num_classes, model, X_val, y_val, y_cols):\n","  # Compute loss and accuracy using model.evaluate()\n","  loss, acc = model.evaluate(X_val, y_val)\n","\n","  y_pred = model.predict(X_val)\n","  print('y_pred', y_pred)\n","  print('y_val', y_val)\n","\n","  if (num_classes == 3) :\n","\n","    # Convert y_val to multiclass format\n","    y_val = np.argmax(y_val, axis=1)\n","\n","    # Convert y_pred to multiclass format\n","    y_pred = np.argmax(y_pred, axis=1)\n","\n","    print('y_pred', y_pred)\n","    print('y_val', y_val)\n","\n","    # Check the type of y_pred_probs\n","    print(\"Type of y_pred using model.predict:\", type(y_pred))\n","    print(\"shape of the y_pred using model.predict:\", y_pred.shape)\n","\n","    # Compute confusion matrix\n","    # y_val_argmax = np.argmax(y_val, axis=1)\n","    # y_pred_argmax = np.argmax(y_pred, axis=1)\n","    # conf_mat = confusion_matrix(y_val_argmax, y_pred_argmax)\n","\n","    conf_mat = mt.confusion_matrix(y_val, y_pred)\n","    print(\"confusion matrix \", conf_mat)\n","\n","    target_names = y_cols\n","\n","    print(\"classification report\", mt.classification_report(y_val, y_pred, target_names=target_names, digits = 3))\n","\n","    # Compute classification report\n","    report = mt.classification_report(y_val, y_pred, target_names=target_names, output_dict=True)\n","    report_df = pd.DataFrame(report).T\n","\n","    print(\"classification report in dataframe - match accuracy with model.evaluate \")\n","    print(report_df)\n","\n","    # Select the first three rows\n","    report_df_top3 = report_df.head(3)\n","\n","    # Calculate average metrics for the first three rows\n","    avg_precision = report_df_top3['precision'].mean()\n","    avg_recall = report_df_top3['recall'].mean()\n","    avg_f1_score = report_df_top3['f1-score'].mean()\n","\n","    print(f\"Average Precision (first 3 classes): {avg_precision:.3f}\")\n","    print(f\"Average Recall (first 3 classes): {avg_recall:.3f}\")\n","    print(f\"Average F1-Score (first 3 classes): {avg_f1_score:.3f}\")\n","\n","    metrics = {\n","        'acc': acc,\n","        'loss': loss,\n","        'conf_mat': conf_mat,\n","        'sens (recall)': avg_recall,\n","        'f1': avg_f1_score,\n","        'prec': avg_precision\n","    }\n","\n","  elif (num_classes == 2) :\n","\n","    # Convert y_val to multiclass format\n","    y_val = np.argmax(y_val, axis=1)\n","\n","    # Convert y_pred to multiclass format\n","    y_pred = np.argmax(y_pred, axis=1)\n","\n","    print('y_pred', y_pred)\n","    print('y_val', y_val)\n","\n","    # Check the type of y_pred_probs\n","    print(\"Type of y_pred using model.predict:\", type(y_pred))\n","    print(\"shape of the y_pred using model.predict:\", y_pred.shape)\n","\n","    # Compute confusion matrix\n","    conf_mat = confusion_matrix(y_val, y_pred)\n","\n","    # Compute confusion matrix\n","    # y_pred = np.argmax(y_pred, axis=1)\n","    # conf_mat = confusion_matrix(y_val, y_pred)\n","\n","    # Compute metrics from confusion matrix\n","    tn, fp, fn, tp = conf_mat.ravel()\n","    precision = precision_score(y_val, y_pred)\n","    recall = recall_score(y_val, y_pred)\n","    f1 = f1_score(y_val, y_pred)\n","\n","    metrics = {\n","        'acc': acc,\n","        'loss': loss,\n","        'conf_mat': conf_mat,\n","        'sens (recall)': recall,\n","        'f1': f1,\n","        'prec': precision,\n","        'tn': tn,\n","        'tp': tp,\n","        'fn': fn,\n","        'fp': fp\n","    }\n","\n","  else :\n","    metrics = {}\n","\n","  return metrics"],"metadata":{"id":"BULz6h_HjOe8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Replacing nan values to 1\n","def nan_to_0(data):\n","\n","    df1 = data.copy()\n","\n","    for idx, row in df1.iterrows():\n","      arr = row['fcmap']\n","      matrix = np.nan_to_num(arr, copy = True, nan = 0.0)\n","      df1.at[idx, 'fcmap'] = matrix\n","\n","    print(df1)\n","\n","    return df1"],"metadata":{"id":"XNvEBOc_IUEv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def computeMinMax(X):\n","  min_matrix = X.min(axis = 0)\n","  max_matrix = X.max(axis = 0)\n","  return (min_matrix, max_matrix)"],"metadata":{"id":"29gD-W9Xidwo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def normalize_instance(X, minn, maxx):\n","  normalised_X = np.zeros(shape=(X.shape[0], X.shape[1]))\n","\n","  for idx, x in np.ndenumerate(X):\n","    if minn[idx] == maxx[idx]:\n","      normalised_X[idx] = x\n","    else:\n","      normalised_X[idx] = (x - minn[idx])/(maxx[idx] - minn[idx])\n","    return normalised_X"],"metadata":{"id":"VPaen_EqiduJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def normalize(X_train, X_val):\n","    # Assuming X_train is your DataFrame with matrices in a single column\n","    matrices = X_train  # Get the values from the 'matrices' column\n","    # Convert the matrices to a 2D NumPy array\n","    X_train_2d = np.stack(matrices)\n","\n","    # Assuming X_train is your DataFrame with matrices in a single column\n","    matrices = X_val  # Get the values from the 'matrices' column\n","    # Convert the matrices to a 2D NumPy array\n","    X_val_2d = np.stack(matrices)\n","\n","    min_matrix, max_matrix = computeMinMax(X_train_2d)\n","\n","    print(\"shape of min matrix\", min_matrix.shape)\n","    print(\"shape of max matrix\", max_matrix.shape)\n","\n","    normalized_instances = []\n","    for instance in X_train_2d:\n","        normalized_instance = normalize_instance(instance, min_matrix, max_matrix)\n","        normalized_instances.append(normalized_instance)\n","\n","    # Convert the list of normalized instances to a NumPy array\n","    X_normalized_trained_2d = np.array(normalized_instances)\n","\n","    normalized_instances = []\n","    for instance in X_val_2d:\n","        normalized_instance = normalize_instance(instance, min_matrix, max_matrix)\n","        normalized_instances.append(normalized_instance)\n","\n","    # Convert the list of normalized instances to a NumPy array\n","    X_normalized_val_2d = np.array(normalized_instances)\n","\n","    return (X_normalized_trained_2d, X_normalized_val_2d)"],"metadata":{"id":"IpA8FXAZjp64"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Padding Matrices\n","# def padding_data(data):\n","#     def pad_matrix(row):\n","#         arr = row['fcmap']\n","#         pad_top = (224 - arr.shape[0]) // 2\n","#         pad_bottom = 224 - arr.shape[0] - pad_top\n","#         pad_left = (224 - arr.shape[1]) // 2\n","#         pad_right = 224 - arr.shape[1] - pad_left\n","#         padded_matrix = np.pad(arr, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant')\n","#         return padded_matrix\n","\n","#     df_pad = data.copy()\n","\n","#     df_pad['fcmap'] = df_pad.apply(lambda row: pad_matrix(row), axis=1)\n","\n","#     return df_pad\n","\n","def padding_data(X, target_shape=(224, 224)):\n","    \"\"\"\n","    Pad each matrix in X_train to the target shape.\n","\n","    Args:\n","        X_train (numpy.ndarray): Input array containing matrices.\n","        target_shape (tuple): Target shape for padding.\n","\n","    Returns:\n","        numpy.ndarray: Padded matrices.\n","    \"\"\"\n","    padded_matrices = []\n","\n","    for matrix in X:\n","        pad_top = (target_shape[0] - matrix.shape[0]) // 2\n","        pad_bottom = target_shape[0] - matrix.shape[0] - pad_top\n","        pad_left = (target_shape[1] - matrix.shape[1]) // 2\n","        pad_right = target_shape[1] - matrix.shape[1] - pad_left\n","\n","        padded_matrix = np.pad(matrix, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant')\n","        padded_matrices.append(padded_matrix)\n","\n","    return np.array(padded_matrices)"],"metadata":{"id":"gvFdoN0ILlTL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def increase_channels(X):\n","    # preparing data for vgg pre-trained\n","    X = np.stack(X).reshape(-1, 132, 132)\n","    print(\"stacking all matrices together\", X.shape)\n","    X = np.expand_dims(X, axis=-1)\n","    print(\"adding channel dimension\", X.shape)\n","    # X = np.repeat(X, 3, axis=-1)\n","    # print(\"increasing channels for vgg\", X.shape)\n","\n","    return X"],"metadata":{"id":"SmZnjUK2EB5I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_dataset(choice):\n","    # Load dataframe from the pickle file\n","    data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ROIxTimeseries/fcmap+psi_data.csv')\n","\n","    if choice == 'A':\n","        # Filter rows where 'adhd' or 'autism' is 1 (keep only ADHD or autism subjects)\n","        data = data[(data['adhd'] == 1) | (data['autism'] == 1)]\n","        y_cols = ['adhd', 'autism']  # Specify the columns for y\n","    elif choice == 'B':\n","        # Filter rows where 'autism' or 'healthy' is 1 (keep only autism or healthy subjects)\n","        data = data[(data['autism'] == 1) | (data['healthy'] == 1)]\n","        y_cols = ['autism', 'healthy']  # Specify the columns for y\n","    elif choice == 'C':\n","        # Filter rows where 'adhd' or 'healthy' is 1 (keep only ADHD or healthy subjects)\n","        data = data[(data['adhd'] == 1) | (data['healthy'] == 1)]\n","        y_cols = ['adhd', 'healthy']  # Specify the columns for y\n","    elif choice == 'D':\n","        # Keep all rows\n","        y_cols = ['adhd', 'autism', 'healthy']  # Specify the columns for y\n","    else:\n","        print(\"Invalid choice. Please enter 'A', 'B', 'C', or 'D'.\")\n","        return pd.DataFrame(), []\n","\n","    print(data)\n","\n","    # df1 = nan_to_0(data)\n","\n","    print(y_cols)\n","    return data, y_cols"],"metadata":{"id":"WmJP3YLbjOca"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def driver(choice):\n","\n","    # choice = input(\"Enter your choice (A, B, C, or D): \").upper()\n","\n","    choice = choice.upper()\n","\n","    df, y_cols = make_dataset(choice)\n","    #print(d.head)\n","\n","    X = df['combined_matrix'].values\n","    print(X.shape)\n","    # print(X)\n","    print(\"type of matrices\", type(X))\n","    y = df[y_cols].values\n","    #y = to_categorical(y, num_classes=3)\n","    # print(y.shape)\n","    # print(y)\n","    print(\"type of label columns\", type(y))\n","\n","    # Get the number of classes\n","    num_classes = y.shape[1]\n","    print(\"No. of classes\", num_classes)\n","\n","    input_shape = X[0].shape\n","    print(\"Input_shape:\", input_shape)\n","\n","    if (num_classes == 2) :\n","      result_df = pd.DataFrame(columns = ['fold','acc','loss','conf_mat', 'sens (recall)','f1','prec', 'tn', 'tp', 'fn', 'fp'])\n","    elif (num_classes == 3) :\n","      result_df = pd.DataFrame(columns = ['fold','acc','loss','conf_mat', 'sens (recall)','f1','prec'])\n","    else :\n","      result_df = {}\n","\n","    # n_splits = n_splits # Number of folds\n","\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n","\n","    tf.keras.backend.clear_session()\n","    for i, (train_index, val_index) in enumerate(kf.split(X, y)):\n","\n","        print(\"FOLD : \", i+1)\n","\n","        X_train, X_val = X[train_index], X[val_index]\n","        y_train, y_val = y[train_index], y[val_index]\n","\n","        # X_normal_train, X_normal_val = normalize(X_train, X_val)\n","\n","        # X_train_pad = padding_data(X_normal_train)\n","        # X_val_pad = padding_data(X_normal_val)\n","\n","        # X_train_1 = increase_channels(X_normal_train)\n","        # X_val_1 = increase_channels(X_normal_val)\n","\n","        # input_shape_2 =  X_train_1[0].shape\n","        # print(\"Input_shape with channel: \", input_shape_2) # in case, sent as argument to get_model()\n","\n","        # compiled_m = get_model(num_classes)\n","        compiled_m = get_model(input_shape,num_classes)\n","\n","        trained_m, history = compile_fit(compiled_m, X_train, np.array(y_train), X_val, np.array(y_val))\n","        plot_history(history, i+1)\n","\n","        scores = eval_model(num_classes, trained_m, X_val, y_val, y_cols)\n","        scores['fold']=i+1\n","        print(\"Scores\", scores)\n","        scores = pd.DataFrame([scores])\n","        result_df = pd.concat([result_df,scores], ignore_index=True)\n","        tf.keras.backend.clear_session()\n","\n","    return result_df"],"metadata":{"id":"M3mrlUZmjOaS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a list of choices\n","# choices = ['A', 'B', 'C', 'D']\n","choices = ['A']\n","\n","# Create an empty dictionary to store the result dataframes\n","result_dfs = {}\n","\n","# Loop through each choice\n","for choice in choices:\n","    # Call the driver() function with the current choice\n","    result_df = driver(choice)\n","\n","    # Store the result dataframe in the dictionary with the choice as the key\n","    result_dfs[choice] = result_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":888},"id":"mly2BAiCrrd1","executionInfo":{"status":"error","timestamp":1718699661152,"user_tz":-330,"elapsed":719,"user":{"displayName":"Karamjot","userId":"14290690433704537570"}},"outputId":"e1fab15a-fe57-4168-ea01-4099f396f85b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["        subject                                    combined_matrix  autism  \\\n","0      subject1  [[[0.         1.        ]\\n  [0.         0.801...       1   \n","1      subject2  [[[0.         1.        ]\\n  [0.         0.910...       1   \n","2      subject3  [[[0.         1.        ]\\n  [0.         0.753...       1   \n","3      subject4  [[[0.         1.        ]\\n  [0.         0.817...       1   \n","4      subject5  [[[0.         1.        ]\\n  [0.         0.747...       1   \n","..          ...                                                ...     ...   \n","105  subject106  [[[0.         1.        ]\\n  [0.         0.719...       0   \n","106  subject107  [[[0.         1.        ]\\n  [0.         0.892...       0   \n","107  subject108  [[[0.         1.        ]\\n  [0.         0.938...       0   \n","108  subject109  [[[0.         1.        ]\\n  [0.         0.930...       0   \n","109  subject110  [[[0.         1.        ]\\n  [0.         0.794...       0   \n","\n","     adhd  healthy  \n","0       0        0  \n","1       0        0  \n","2       0        0  \n","3       0        0  \n","4       0        0  \n","..    ...      ...  \n","105     1        0  \n","106     1        0  \n","107     1        0  \n","108     1        0  \n","109     1        0  \n","\n","[110 rows x 5 columns]\n","['adhd', 'autism']\n","(110,)\n","type of matrices <class 'numpy.ndarray'>\n","type of label columns <class 'numpy.ndarray'>\n","No. of classes 2\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'str' object has no attribute 'shape'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-5d4a0ff8973b>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Call the driver() function with the current choice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mresult_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Store the result dataframe in the dictionary with the choice as the key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-d4a0eb429972>\u001b[0m in \u001b[0;36mdriver\u001b[0;34m(choice)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No. of classes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input_shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"]}]},{"cell_type":"code","source":["print(result_dfs['A'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"TiBtoUTLr1W2","executionInfo":{"status":"error","timestamp":1718699661838,"user_tz":-330,"elapsed":689,"user":{"displayName":"Karamjot","userId":"14290690433704537570"}},"outputId":"591d35e5-abca-4d1c-c03a-616f7b5b15e9"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'A'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-b31fa45fb674>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyError\u001b[0m: 'A'"]}]},{"cell_type":"code","source":["print(result_dfs['B'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"in8Zi0MBr6bV","executionInfo":{"status":"ok","timestamp":1717663557116,"user_tz":-330,"elapsed":6,"user":{"displayName":"Karamjot","userId":"14290690433704537570"}},"outputId":"1b5a577d-8912-4373-b705-566b02daac05","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  fold       acc      loss          conf_mat  sens (recall)   f1      prec tn  \\\n","0    1  0.333333  1.508365  [[4, 0], [8, 0]]            0.0  0.0  0.000000  4   \n","1    2  0.500000  0.707297  [[6, 0], [6, 0]]            0.0  0.0  0.000000  6   \n","2    3  0.666667  0.639697  [[8, 0], [4, 0]]            0.0  0.0  0.000000  8   \n","3    4  0.666667  0.839063  [[0, 4], [0, 8]]            1.0  0.8  0.666667  0   \n","4    5  0.583333  0.682799  [[7, 0], [5, 0]]            0.0  0.0  0.000000  7   \n","\n","  tp fn fp  \n","0  0  8  0  \n","1  0  6  0  \n","2  0  4  0  \n","3  8  0  4  \n","4  0  5  0  \n"]}]},{"cell_type":"code","source":["print(result_dfs['C'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUvQ70JWr6RV","executionInfo":{"status":"ok","timestamp":1717663557116,"user_tz":-330,"elapsed":5,"user":{"displayName":"Karamjot","userId":"14290690433704537570"}},"outputId":"92387940-145a-42da-859e-3a17b23e7230","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  fold       acc      loss          conf_mat  sens (recall)        f1  \\\n","0    1  0.615385  0.718446  [[0, 5], [0, 8]]            1.0  0.761905   \n","1    2  0.583333  0.822346  [[7, 0], [5, 0]]            0.0  0.000000   \n","2    3  0.500000  0.716370  [[0, 6], [0, 6]]            1.0  0.666667   \n","3    4  0.416667  0.719656  [[5, 0], [7, 0]]            0.0  0.000000   \n","4    5  0.583333  0.775630  [[7, 0], [5, 0]]            0.0  0.000000   \n","\n","       prec tn tp fn fp  \n","0  0.615385  0  8  0  5  \n","1  0.000000  7  0  5  0  \n","2  0.500000  0  6  0  6  \n","3  0.000000  5  0  7  0  \n","4  0.000000  7  0  5  0  \n"]}]},{"cell_type":"code","source":["print(result_dfs['D'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"apjP_FSAr6Oe","executionInfo":{"status":"ok","timestamp":1717663557116,"user_tz":-330,"elapsed":3,"user":{"displayName":"Karamjot","userId":"14290690433704537570"}},"outputId":"b975f865-1d3d-4001-e60e-415099a2fb80","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  fold       acc      loss                            conf_mat  sens (recall)  \\\n","0    1  0.444444  1.066631   [[0, 6, 0], [0, 8, 0], [0, 4, 0]]       0.333333   \n","1    2  0.222222  1.148250   [[0, 6, 0], [0, 4, 0], [0, 8, 0]]       0.333333   \n","2    3  0.555556  1.027540  [[0, 4, 0], [0, 10, 0], [0, 4, 0]]       0.333333   \n","3    4  0.388889  1.090923  [[0, 0, 10], [0, 0, 1], [0, 0, 7]]       0.333333   \n","4    5  0.222222  1.500596   [[4, 0, 0], [6, 0, 0], [8, 0, 0]]       0.333333   \n","\n","         f1      prec  \n","0  0.205128  0.148148  \n","1  0.121212  0.074074  \n","2  0.238095  0.185185  \n","3  0.186667  0.129630  \n","4  0.121212  0.074074  \n"]}]}]}